Traceback (most recent call last):
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Users/mehdimir/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------

L.backward()
L.backward()

------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[12], line 1[0m
[0;32m----> 1[0m [43mL[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[43m)[49m
[1;32m      2[0m L[38;5;241m.[39mbackward()

File [0;32m~/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/torch/_tensor.py:625[0m, in [0;36mTensor.backward[0;34m(self, gradient, retain_graph, create_graph, inputs)[0m
[1;32m    615[0m [38;5;28;01mif[39;00m has_torch_function_unary([38;5;28mself[39m):
[1;32m    616[0m     [38;5;28;01mreturn[39;00m handle_torch_function(
[1;32m    617[0m         Tensor[38;5;241m.[39mbackward,
[1;32m    618[0m         ([38;5;28mself[39m,),
[0;32m   (...)[0m
[1;32m    623[0m         inputs[38;5;241m=[39minputs,
[1;32m    624[0m     )
[0;32m--> 625[0m [43mtorch[49m[38;5;241;43m.[39;49m[43mautograd[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m
[1;32m    626[0m [43m    [49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43mgradient[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[38;5;241;43m=[39;49m[43minputs[49m
[1;32m    627[0m [43m[49m[43m)[49m

File [0;32m~/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/torch/autograd/__init__.py:354[0m, in [0;36mbackward[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)[0m
[1;32m    349[0m     retain_graph [38;5;241m=[39m create_graph
[1;32m    351[0m [38;5;66;03m# The reason we repeat the same comment below is that[39;00m
[1;32m    352[0m [38;5;66;03m# some Python versions print out the first line of a multi-line function[39;00m
[1;32m    353[0m [38;5;66;03m# calls in the traceback and some print out the last line[39;00m
[0;32m--> 354[0m [43m_engine_run_backward[49m[43m([49m
[1;32m    355[0m [43m    [49m[43mtensors[49m[43m,[49m
[1;32m    356[0m [43m    [49m[43mgrad_tensors_[49m[43m,[49m
[1;32m    357[0m [43m    [49m[43mretain_graph[49m[43m,[49m
[1;32m    358[0m [43m    [49m[43mcreate_graph[49m[43m,[49m
[1;32m    359[0m [43m    [49m[43minputs_tuple[49m[43m,[49m
[1;32m    360[0m [43m    [49m[43mallow_unreachable[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m
[1;32m    361[0m [43m    [49m[43maccumulate_grad[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m
[1;32m    362[0m [43m[49m[43m)[49m

File [0;32m~/miniforge3/envs/jupyterbook/lib/python3.10/site-packages/torch/autograd/graph.py:841[0m, in [0;36m_engine_run_backward[0;34m(t_outputs, *args, **kwargs)[0m
[1;32m    839[0m     unregister_hooks [38;5;241m=[39m _register_logging_hooks_on_whole_graph(t_outputs)
[1;32m    840[0m [38;5;28;01mtry[39;00m:
[0;32m--> 841[0m     [38;5;28;01mreturn[39;00m [43mVariable[49m[38;5;241;43m.[39;49m[43m_execution_engine[49m[38;5;241;43m.[39;49m[43mrun_backward[49m[43m([49m[43m  [49m[38;5;66;43;03m# Calls into the C++ engine to run the backward pass[39;49;00m
[1;32m    842[0m [43m        [49m[43mt_outputs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m
[1;32m    843[0m [43m    [49m[43m)[49m  [38;5;66;03m# Calls into the C++ engine to run the backward pass[39;00m
[1;32m    844[0m [38;5;28;01mfinally[39;00m:
[1;32m    845[0m     [38;5;28;01mif[39;00m attach_logging_hooks:

[0;31mRuntimeError[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.

