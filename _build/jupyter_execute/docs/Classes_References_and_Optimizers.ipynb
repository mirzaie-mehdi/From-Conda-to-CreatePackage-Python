{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b1f6d2",
   "metadata": {},
   "source": [
    "# Understanding Classes, References, and Parameter Updates\n",
    "\n",
    "This notebook is designed to strengthen your understanding of **Python classes, objects, and references**, using a minimal optimizer example inspired by neural networks.\n",
    "\n",
    "The core question we answer is:\n",
    "\n",
    "**How can an optimizer update parameters of many Layer objects when it only sees a flat list of parameters?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736982b3",
   "metadata": {},
   "source": [
    "## Key Idea\n",
    "\n",
    "In Python:\n",
    "\n",
    "- Variables store **references** to objects, not copies\n",
    "- Attributes like `layer.W` are themselves objects\n",
    "- Lists can store references to those same objects\n",
    "\n",
    "If two names reference the same mutable object, modifying it through one name affects the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6379fa",
   "metadata": {},
   "source": [
    "## Mathematical Context (Minimal)\n",
    "\n",
    "In gradient descent, each parameter $p$ is updated as:\n",
    "\n",
    "$p \\leftarrow p - \\eta g$\n",
    "\n",
    "where $\\eta$ is the learning rate and $g = \\frac{\\partial L}{\\partial p}$.\n",
    "\n",
    "The important part here is **how this update reaches the correct object in memory**, not the calculus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ec715",
   "metadata": {},
   "source": [
    "## Part A — A Minimal Layer Class\n",
    "\n",
    "We start with a very small class that mimics a neural network layer.\n",
    "It has a parameter `W`, a gradient `dW`, and exposes them via `params()` and `grads()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923453b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyLayer:\n",
    "    def __init__(self, W, dW):\n",
    "        self.W = W      # parameter (mutable object)\n",
    "        self.dW = dW    # gradient\n",
    "\n",
    "    def params(self):\n",
    "        # Returns a reference, NOT a copy\n",
    "        return [self.W]\n",
    "\n",
    "    def grads(self):\n",
    "        return [self.dW]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b718ce",
   "metadata": {},
   "source": [
    "### Experiment A1 — Reference behavior\n",
    "\n",
    "We will modify the parameter through the list returned by `params()` and observe the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73566132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modification:\n",
      "layer.W = [10, 20]\n",
      "params[0] = [10, 20]\n",
      "\n",
      "After modification through params:\n",
      "layer.W = [9, 20]\n",
      "params[0] = [9, 20]\n"
     ]
    }
   ],
   "source": [
    "layer = ToyLayer(W=[10, 20], dW=[1, 1])\n",
    "params = layer.params()\n",
    "\n",
    "print('Before modification:')\n",
    "print('layer.W =', layer.W)\n",
    "print('params[0] =', params[0])\n",
    "\n",
    "params[0][0] -= 1\n",
    "\n",
    "print('\\nAfter modification through params:')\n",
    "print('layer.W =', layer.W)\n",
    "print('params[0] =', params[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eeda6d",
   "metadata": {},
   "source": [
    "**Explanation:** `params[0]` and `layer.W` reference the same object. Changing one changes the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1faf807",
   "metadata": {},
   "source": [
    "## Part B — A Minimal Optimizer\n",
    "\n",
    "The optimizer does not know what a Layer is. It only assumes the object passed to it has `params()` and `grads()` methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45647809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySGD:\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, model):\n",
    "        for p, g in zip(model.params(), model.grads()):\n",
    "            p[0] = p[0] - self.lr * g[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e60c4",
   "metadata": {},
   "source": [
    "### Experiment B1 — Updating a single layer via the optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34531950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before step: [10, 20]\n",
      "After step : [9.9, 20]\n"
     ]
    }
   ],
   "source": [
    "layer = ToyLayer(W=[10, 20], dW=[1, 1])\n",
    "opt = ToySGD(lr=0.1)\n",
    "\n",
    "print('Before step:', layer.W)\n",
    "opt.step(layer)\n",
    "print('After step :', layer.W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2bcc3e",
   "metadata": {},
   "source": [
    "**Explanation:** The optimizer updates the same object referenced by the layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151911c",
   "metadata": {},
   "source": [
    "## Part C — Multiple Layers with a Sequential Container\n",
    "\n",
    "We now collect parameters from multiple layers into a flat list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032c8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySequential:\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = list(layers)\n",
    "\n",
    "    def params(self):\n",
    "        ps = []\n",
    "        for layer in self.layers:\n",
    "            ps.extend(layer.params())\n",
    "        return ps\n",
    "\n",
    "    def grads(self):\n",
    "        gs = []\n",
    "        for layer in self.layers:\n",
    "            gs.extend(layer.grads())\n",
    "        return gs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7162d36",
   "metadata": {},
   "source": [
    "### Experiment C1 — Updating multiple layers at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2eead79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before step:\n",
      "layer1.W = [10, 20]\n",
      "layer2.W = [100, 200]\n",
      "\n",
      "After step:\n",
      "layer1.W = [9.9, 20]\n",
      "layer2.W = [99.0, 200]\n"
     ]
    }
   ],
   "source": [
    "layer1 = ToyLayer(W=[10, 20], dW=[1, 1])\n",
    "layer2 = ToyLayer(W=[100, 200], dW=[10, 10])\n",
    "\n",
    "model = ToySequential(layer1, layer2)\n",
    "opt = ToySGD(lr=0.1)\n",
    "\n",
    "print('Before step:')\n",
    "print('layer1.W =', layer1.W)\n",
    "print('layer2.W =', layer2.W)\n",
    "\n",
    "opt.step(model)\n",
    "\n",
    "print('\\nAfter step:')\n",
    "print('layer1.W =', layer1.W)\n",
    "print('layer2.W =', layer2.W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe4263",
   "metadata": {},
   "source": [
    "## Final Mental Model\n",
    "\n",
    "1. Parameters live inside layer objects\n",
    "2. `params()` returns references to those parameters\n",
    "3. Lists store references, not copies\n",
    "4. Optimizers modify parameters in place\n",
    "\n",
    "**Optimizers do not update layers — they update the objects layers reference.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}