{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943df667",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder on MNIST (PyTorch) + PCA and t-SNE Latent Visualizations\n",
    "\n",
    "This notebook implements a **denoising autoencoder** trained on MNIST.  \n",
    "It also visualizes the **latent space** (encoder output) using **PCA** and **t-SNE**, and shows how the **decoder** maps latent codes back to images.\n",
    "\n",
    "**Denoising objective:** feed a *noisy* input \\(\\tilde{x}\\) but reconstruct the *clean* target \\(x\\):\n",
    "\\[\n",
    "\\min_\\theta \\; \\mathbb{E}\\left[\\mathcal{L}\\big(f_\\theta(\\tilde{x}),\\; x\\big)\\right].\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515d31c",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "If needed:\n",
    "```bash\n",
    "pip install torch torchvision scikit-learn matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd78e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a01f7",
   "metadata": {},
   "source": [
    "## 2) Data\n",
    "\n",
    "We use `ToTensor()` only so MNIST pixels are in \\([0,1]\\), matching a decoder ending with `Sigmoid()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104a489",
   "metadata": {},
   "source": [
    "## 3) Model (Encoder/Decoder)\n",
    "\n",
    "Inspired by your earlier autoencoder:\n",
    "\n",
    "- Encoder: 784 → 256 → 64 → latent\n",
    "- Decoder: latent → 64 → 256 → 784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ac2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, latent_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Unflatten(1, (1, 28, 28)),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "model = AutoEncoder(latent_dim=16).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe6dee",
   "metadata": {},
   "source": [
    "## 4) Denoising: Noise Function\n",
    "\n",
    "We add Gaussian noise and clamp to \\([0,1]\\):\n",
    "\\[\n",
    "\\tilde{x} = \\mathrm{clip}(x + \\epsilon, 0, 1), \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2).\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, sigma=0.35):\n",
    "    noise = sigma * torch.randn_like(x)\n",
    "    x_noisy = torch.clamp(x + noise, 0.0, 1.0)\n",
    "    return x_noisy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c43f21",
   "metadata": {},
   "source": [
    "## 5) Training\n",
    "\n",
    "We optimize reconstruction of the **clean** image from its **noisy** version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74add209",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def run_epoch(model, loader, train=True, sigma=0.35):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, n = 0.0, 0\n",
    "\n",
    "    for x, _ in loader:\n",
    "        x = x.to(device)\n",
    "        x_noisy = add_noise(x, sigma=sigma)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            x_hat = model(x_noisy)\n",
    "            loss = criterion(x_hat, x)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    return total_loss / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "sigma = 0.35\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = run_epoch(model, train_loader, train=True, sigma=sigma)\n",
    "    test_loss  = run_epoch(model, test_loader,  train=False, sigma=sigma)\n",
    "    print(f\"Epoch {epoch:02d} | train loss: {train_loss:.4f} | test loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226b8a2",
   "metadata": {},
   "source": [
    "## 6) Visual Check: Clean vs Noisy vs Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ae52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def show_denoising_examples(model, loader, sigma=0.35, n=10):\n",
    "    model.eval()\n",
    "    x, _ = next(iter(loader))\n",
    "    x = x[:n].to(device)\n",
    "\n",
    "    x_noisy = add_noise(x, sigma=sigma)\n",
    "    x_hat = model(x_noisy)\n",
    "\n",
    "    x = x.cpu()\n",
    "    x_noisy = x_noisy.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(3, n, figsize=(1.4*n, 4.2))\n",
    "    for i in range(n):\n",
    "        axes[0, i].imshow(x[i, 0], cmap=\"gray\"); axes[0, i].axis(\"off\")\n",
    "        axes[1, i].imshow(x_noisy[i, 0], cmap=\"gray\"); axes[1, i].axis(\"off\")\n",
    "        axes[2, i].imshow(x_hat[i, 0], cmap=\"gray\"); axes[2, i].axis(\"off\")\n",
    "\n",
    "    axes[0, 0].set_title(\"Clean\")\n",
    "    axes[1, 0].set_title(\"Noisy\")\n",
    "    axes[2, 0].set_title(\"Reconstruction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_denoising_examples(model, test_loader, sigma=sigma, n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98295343",
   "metadata": {},
   "source": [
    "## 7) Extract Latent Codes\n",
    "\n",
    "We collect encoder outputs \\(z\\) and labels to visualize structure in the latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def collect_latents(model, loader, max_items=5000):\n",
    "    model.eval()\n",
    "    Z_list, y_list = [], []\n",
    "    count = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        z = model.encoder(x)\n",
    "        Z_list.append(z.cpu().numpy())\n",
    "        y_list.append(y.numpy())\n",
    "        count += x.size(0)\n",
    "        if count >= max_items:\n",
    "            break\n",
    "\n",
    "    Z = np.concatenate(Z_list, axis=0)[:max_items]\n",
    "    y = np.concatenate(y_list, axis=0)[:max_items]\n",
    "    return Z, y\n",
    "\n",
    "Z, y = collect_latents(model, test_loader, max_items=5000)\n",
    "Z.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e55a40",
   "metadata": {},
   "source": [
    "## 8) PCA Plot (Latent Space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b670dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_pca = PCA(n_components=2, random_state=0).fit_transform(Z)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(Z_pca[:, 0], Z_pca[:, 1], c=y, s=6)\n",
    "plt.title(\"Latent Space (PCA, 2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3379d",
   "metadata": {},
   "source": [
    "## 9) t-SNE Plot (Latent Space)\n",
    "\n",
    "t-SNE is non-linear and often shows clusters more clearly. It is slower than PCA, so we use a subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tsne = min(3000, Z.shape[0])\n",
    "Z_tsne = TSNE(n_components=2, perplexity=30, init=\"pca\", learning_rate=\"auto\", random_state=0).fit_transform(Z[:n_tsne])\n",
    "y_tsne = y[:n_tsne]\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(Z_tsne[:, 0], Z_tsne[:, 1], c=y_tsne, s=6)\n",
    "plt.title(\"Latent Space (t-SNE, 2D)\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896f290",
   "metadata": {},
   "source": [
    "## 10) Visualizing the Decoder (Manifold via PCA Directions)\n",
    "\n",
    "To “show the decoder part”, we decode a grid of latent points.\n",
    "\n",
    "Because the latent space is 16D, we build a 2D grid in the **first two PCA directions** of the latent codes:\n",
    "\\[\n",
    "z \\approx \\mu + u_1\\alpha + u_2\\beta\n",
    "\\]\n",
    "and decode each \\(z\\) into an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def decoder_manifold_via_pca(model, Z, grid=10, span=2.5):\n",
    "    model.eval()\n",
    "\n",
    "    pca = PCA(n_components=2, random_state=0)\n",
    "    pca.fit(Z)\n",
    "\n",
    "    mu = Z.mean(axis=0)          # (latent_dim,)\n",
    "    U = pca.components_          # (2, latent_dim)\n",
    "\n",
    "    xs = np.linspace(-span, span, grid)\n",
    "    ys = np.linspace(-span, span, grid)\n",
    "\n",
    "    rows = []\n",
    "    for yv in ys[::-1]:\n",
    "        cols = []\n",
    "        for xv in xs:\n",
    "            z = mu + U[0] * xv + U[1] * yv\n",
    "            z_t = torch.tensor(z, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            x_hat = model.decoder(z_t).squeeze(0).detach().cpu().numpy()[0]  # (28,28)\n",
    "            cols.append(x_hat)\n",
    "        rows.append(np.concatenate(cols, axis=1))\n",
    "\n",
    "    canvas = np.concatenate(rows, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(canvas, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Decoder Manifold (Grid in PCA Latent Space)\")\n",
    "    plt.show()\n",
    "\n",
    "decoder_manifold_via_pca(model, Z, grid=10, span=2.5)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
